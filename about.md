---
layout: page
title: About
---

Hi there. I'm [Michaël Trazzi](https://michaeltrazzi.com), your host for The Inside View podcast, and here's the first definition for what's an "inside view" on google:

> "Whereas the inside view attempts to make predictions based on an understanding of the details of a problem, the outside view—also called reference class forecasting—instead looks at similar past situations and predicts based on those outcomes."

The goal of this podcast is to create a place where people discuss their inside views about existential risk from AI (including AI Alignment, AI Governance, AI timelines, and everything else that could be decision-relevant for thinking about existential risk from AI).

I started these interviews because I was having interesting conversations online and I thought it made sense to record them.

You could start with the popular episodes, namely [Connor Leahy](https://theinsideview.ai/connor2), [Ethan](https://theinsideview.ai/ethan2) [Caballero](https://theinsideview.ai/ethan) and [Robert Miles](https://theinsideview.ai/rob), or the underappreciated ones (high like/dislike ratio on Youtube, but not a lot of views), aka [Shahar Avin](https://theinsideview.ai/shahar), [Alex Lawsen](https://theinsideview.ai/alex) and [Robert Long](https://theinsideview.ai/roblong).

If you're into those sorts of things, you can subscribe to the website's [RSS feed](https://theinsideview.ai/feed.xml) and donate via [Paypal](https://paypal.me/michaeltrazzi). If you have any feedback about the podcast, suggestions or just want to say hi, feel free to reach out by [email](michael with a dot that is totally optional trazzi at gmail dot com). You can also reach me on [Twitter](https://twitter.com/MichaelTrazzi), or find shorter clips on [TikTok](https://www.tiktok.com/@theinsideview.ai)/[Instagram](http://instagram.com/theinsideview.ai).
