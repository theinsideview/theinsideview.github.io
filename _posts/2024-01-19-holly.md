---
layout: post
title: "Holly Elmore on AI Pause Advocacy"
category: podcast
permalink: holly
youtubeId:
spotifyId:
---

{% include youtubePlayer.html id=page.youtubeId %}
{% include spotifyPlayer.html id=page.spotifyId %}

Holly

<sup><sub><i>(Note: as always, conversation is ~2h long, so feel free to click on any sub-topic of your liking in the outline below and then come back to the outline by clicking on the green arrow</i></sub></sup> ⬆<sup><sub><i>)</i></sub></sup>

# Outline

* [Highlighted Quotes](#highlighted-quotes)
* [Intro](#intro)

# Highlighted Quotes

# Pause AI Protests Organized By Holly

## Background on Holly And Pause

**Michaël**: So for people who are just joining, it's a podcast Twitter space with Holly Hillmore, which I'll call here an advocate of AI pause. People will be asking questions and speaking in the middle. Probably at the beginning, I'll just start by talking with Holly a little bit, one-on-one. But for people who are not familiar, maybe just give some context about what's AI pause and maybe Holly, you can start with who is Holly Hillmore.

**Holly**: Okay, I'm Holly Elmore. You guys might know me from Twitter. When I say pause, I mean an indefinite global pause on the development of more advanced AI than we currently have. So, you know, training that takes significantly more resources. What I'm asking for is a global indefinite pause. Before this, I worked at a think tank and I have a long history in effective altruism. That was where I was exposed to AI safety information over the last 10 years. I didn't personally work on it until April with the [FLI pause letter](https://futureoflife.org/open-letter/pause-giant-ai-experiments/).

**Holly**: These polls came out showing that there was just wild support. We're regulating AI and we'd always said in AI safety that the reason that we weren't pursuing, you know, popular support or government regulation was that the public just doesn't understand the issue. It bounces off of them. If you tell politicians, they think you're crazy and you lose your capital to have any influence to help the issue at all.

**Holly**: But when it was clear to me that the overtime window had shifted, I was, okay, absolutely. This is the next move that we should be doing. And then people weren't as into it as I thought they were. And so I ended up ultimately doing it myself, working on incorporating Pause AI US to be the vehicle for that kind of work in the US.

##

**Holly**: The [first protest](https://metaprotest.org/) I did was at the Meta building in San Francisco and it was against open sourcing of LLMs. And then the second protest, it was in a park in San Francisco and it was aimed at the [UK AI safety summit](https://www.aisafetysummit.gov.uk/) and it was part of a total of seven protests around the world that were aimed toward the summit, trying to raise awareness of the summit should be about safety as the summit approached, it kind of went back and forth. We hear a really safety focused message and we think, good, the summit will be about coordinating around safety. And then there'd be a message about, well, you know, we don't want to stop industry and, we'd get kind of worried, don't lose focus guys. This isn't coordinating about innovation. The point was supposed to be safety. The intent of that protest was to be part of a worldwide thing and to have that message that the safety summit should be focused on safety. That was the one where we wore orange shirts and got a little more internet attention.

**Holly**: The first one was more like 10 people in front of the Meta office giving flyers and everything. And the second one is

**Holly**: 25.

**Michaël**: Sorry, I didn't count. For the UK AI summit. Did you get an outcome of people talking about the protests during the summit?

**Holly**: It was a lot less clear what the impact was there. Meta was the first protest I had ever done. People learn a lot, you know, it doesn't have to be a big success, but actually I think it was more successful than the second protest. That might be because it's... I'm not sure. We didn't get as much media attention as we thought we would. Maybe that was because the Meta protest was kind of, that was the, the novel, first AI safety protest in the US or first Meta one. And then it was less novel, maybe also less clear what the conflict was when you're in front of a building, you know, and there's this clear narrative of, we want them to stop doing what they're doing versus we're in solidarity with other people at other locations talking about the summit in another country.

**Holly**: It might've just been too tenuous. I really don't know. I have not cracked what makes the media interested. They were very interested in the Meta protests. Much more than I anticipated. I almost couldn't handle the level of interest that they showed. And then, I was more ready for that to happen again for the second protest. And then we experimented more with different ways of slicing and dicing the images here and trying to get that kind of engagement. I am not sure that's the direction I'll continue to go, but it was interesting to get different things out of the different events.

**Michaël**: You said you had a lot of media attention. Do you have journalists coming and asking you what's pause AI, what's X-risk, those kinds of things?

**Holly**: Yeah. A lot of, um, I suspect that with Meta, especially that a lot of journalists, already had things they wanted to say about Meta and they just, this made it a story and, so they came to me and they wanted my opinion on other ways that Meta had pissed people off and how that fit in. You have to be aware of their agendas or what makes, um, what makes it news as far as, as they're concerned, but definitely the conflict with Meta was more interesting to journalists than just in general talking about what the government should do. What, uh, government institutions should do, which I'll bear in mind, you know, my next planned protest is that open AI, uh, in part for that reason, it just seems like it's easier for people to understand what your complaint is when the characters are also more clear.


**Holly**: If you're just at an AGI company, it's kind of clear, who the characters are, they're the activists and there's the company. I mean, imagine if the climate change activists and the oil company executives all hung out together and dated and went to parties together, it's just... it's real. It's very strange. we're the people who care about AI safety. It's over this huge spread of interest and it's over this huge spread of personalities. And it's a very common, tech personality to think that protesting is kind of the blue tribe thing. And, that's not really for them. And if you're smart, you figure out how to make enough money or do a backroom deal. You won't have to show up. And there's a really big difference between the kind of person who thinks, yeah, let's just have events and they'll slowly grow, which is how I feel. And then there's the kind of person who feels it is embarrassing, who would never do it. If too few people show up, if your room looks empty, that's it, you look weak. That's over. So you can't start that way. I just don't really get that. I think that that's just clearly not true. All my organizing has started slow and small and gotten bigger. But yeah, there's something that's very vulnerable and exposing about protests to a lot of people. And I think that's fine. You know, they don't have to protest.
